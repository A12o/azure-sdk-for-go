package filesystem

// Copyright (c) Microsoft and contributors.  All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

import (
	"context"
	"encoding/json"
	"fmt"
	"github.com/Azure/azure-pipeline-go/pipeline"
	"io"
	"io/ioutil"
	"net/http"
	"net/url"
)

// Client is the creates an Azure Data Lake Store filesystem client.
type Client struct {
	ManagementClient
}

// NewClient creates an instance of the Client client.
func NewClient(url url.URL, p pipeline.Pipeline) Client {
	return Client{NewManagementClient(url, p)}
}

// Append appends to the specified file. This method does not support multiple concurrent appends to the file. NOTE:
// Concurrent append and normal (serial) append CANNOT be used interchangeably. Once a file has been appended to using
// either append option, it can only be appended to using that append option. Use the ConcurrentAppend option if you
// would like support for concurrent appends.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. directFilePath is the Data
// Lake Store path (starting with '/') of the file to which to append. streamContents is the file contents to include
// when appending to the file. streamContents will be closed upon successful return. Callers should ensure closure when
// receiving an error.offset is the optional offset in the stream to begin the append operation. Default is to append
// at the end of the stream.
func (client Client) Append(ctx context.Context, accountName string, directFilePath string, body io.ReadSeeker, offset *int64) (*http.Response, error) {
	if err := validate([]validation{
		{targetValue: streamContents,
			constraints: []constraint{{target: "streamContents", name: null, rule: true, chain: nil}}}}); err != nil {
		return nil, err
	}
	req, err := client.appendPreparer(accountName, directFilePath, body, offset)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.appendResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// appendPreparer prepares the Append request.
func (client Client) appendPreparer(accountName string, directFilePath string, body io.ReadSeeker, offset *int64) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("POST", client.url, body)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if offset != nil {
		params.Set("offset", fmt.Sprintf("%v", *offset))
	}
	params.Set("op", "APPEND")
	params.Set("append", "true")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// appendResponder handles the response to the Append request.
func (client Client) appendResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// CheckAccess checks if the specified access is available at the given path.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory for which to check access. fsaction is file system operation
// read/write/execute in string form, matching regex pattern '[rwx-]{3}'
func (client Client) CheckAccess(ctx context.Context, accountName string, pathParameter string, fsaction *string) (*http.Response, error) {
	req, err := client.checkAccessPreparer(accountName, pathParameter, fsaction)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.checkAccessResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// checkAccessPreparer prepares the CheckAccess request.
func (client Client) checkAccessPreparer(accountName string, pathParameter string, fsaction *string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if fsaction != nil {
		params.Set("fsaction", *fsaction)
	}
	params.Set("op", "CHECKACCESS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// checkAccessResponder handles the response to the CheckAccess request.
func (client Client) checkAccessResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Concat concatenates the list of source files into the destination file, removing all source files upon success.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. destinationPath is the Data
// Lake Store path (starting with '/') of the destination file resulting from the concatenation. sources is a list of
// comma seperated Data Lake Store paths (starting with '/') of the files to concatenate, in the order in which they
// should be concatenated.
func (client Client) Concat(ctx context.Context, accountName string, destinationPath string, sources []string) (*http.Response, error) {
	if err := validate([]validation{
		{targetValue: sources,
			constraints: []constraint{{target: "sources", name: null, rule: true, chain: nil}}}}); err != nil {
		return nil, err
	}
	req, err := client.concatPreparer(accountName, destinationPath, sources)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.concatResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// concatPreparer prepares the Concat request.
func (client Client) concatPreparer(accountName string, destinationPath string, sources []string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("POST", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("sources", fmt.Sprintf("%v", sources, ","))
	params.Set("op", "CONCAT")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// concatResponder handles the response to the Concat request.
func (client Client) concatResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// ConcurrentAppend appends to the specified file. This method supports multiple concurrent appends to the file. NOTE:
// ConcurrentAppend and normal (serial) Append CANNOT be used interchangeably; once a file has been appended to using
// either of these append options, it can only be appended to using that append option. ConcurrentAppend DOES NOT
// guarantee order and can result in duplicated data landing in the target file. In order to close a file after using
// ConcurrentAppend, call the Flush method.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. filePath is the Data Lake
// Store path (starting with '/') of the file to which to append using concurrent append. streamContents is the file
// contents to include when appending to the file. streamContents will be closed upon successful return. Callers should
// ensure closure when receiving an error.transferEncoding is indicates the data being sent to the server is being
// streamed in chunks. appendMode is indicates the concurrent append call should create the file if it doesn't exist or
// just open the existing file for append
func (client Client) ConcurrentAppend(ctx context.Context, accountName string, filePath string, body io.ReadSeeker, transferEncoding string, appendMode AppendModeType) (*http.Response, error) {
	if err := validate([]validation{
		{targetValue: streamContents,
			constraints: []constraint{{target: "streamContents", name: null, rule: true, chain: nil}}}}); err != nil {
		return nil, err
	}
	req, err := client.concurrentAppendPreparer(accountName, filePath, body, transferEncoding, appendMode)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.concurrentAppendResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// concurrentAppendPreparer prepares the ConcurrentAppend request.
func (client Client) concurrentAppendPreparer(accountName string, filePath string, body io.ReadSeeker, transferEncoding string, appendMode AppendModeType) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("POST", client.url, body)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if appendMode != AppendModeNone {
		params.Set("appendMode", fmt.Sprintf("%v", appendMode))
	}
	params.Set("op", "CONCURRENTAPPEND")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	req.Header.Set("Transfer-Encoding", transferEncoding)
	return req, nil
}

// concurrentAppendResponder handles the response to the ConcurrentAppend request.
func (client Client) concurrentAppendResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Create creates a file with optionally specified content.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. directFilePath is the Data
// Lake Store path (starting with '/') of the file to create. streamContents is the file contents to include when
// creating the file. This parameter is optional, resulting in an empty file if not specified. streamContents will be
// closed upon successful return. Callers should ensure closure when receiving an error.overwrite is the indication of
// if the file should be overwritten.
func (client Client) Create(ctx context.Context, accountName string, directFilePath string, body io.ReadSeeker, overwrite *bool) (*http.Response, error) {
	req, err := client.createPreparer(accountName, directFilePath, body, overwrite)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.createResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// createPreparer prepares the Create request.
func (client Client) createPreparer(accountName string, directFilePath string, body io.ReadSeeker, overwrite *bool) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, body)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if overwrite != nil {
		params.Set("overwrite", fmt.Sprintf("%v", *overwrite))
	}
	params.Set("op", "CREATE")
	params.Set("write", "true")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// createResponder handles the response to the Create request.
func (client Client) createResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK, http.StatusCreated)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Delete deletes the requested file or directory, optionally recursively.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. filePath is the Data Lake
// Store path (starting with '/') of the file or directory to delete. recursive is the optional switch indicating if
// the delete should be recursive
func (client Client) Delete(ctx context.Context, accountName string, filePath string, recursive *bool) (*FileOperationResult, error) {
	req, err := client.deletePreparer(accountName, filePath, recursive)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.deleteResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileOperationResult), err
}

// deletePreparer prepares the Delete request.
func (client Client) deletePreparer(accountName string, filePath string, recursive *bool) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("DELETE", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if recursive != nil {
		params.Set("recursive", fmt.Sprintf("%v", *recursive))
	}
	params.Set("op", "DELETE")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// deleteResponder handles the response to the Delete request.
func (client Client) deleteResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileOperationResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// Flush flushes the specified file to the store. This forces an update to the metadata of the file (returned from
// GetFileStatus), and is required by ConcurrentAppend once the file is done to populate finalized metadata.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. flushFilePath is the Data Lake
// Store path (starting with '/') of the file to which to flush.
func (client Client) Flush(ctx context.Context, accountName string, flushFilePath string) (*http.Response, error) {
	req, err := client.flushPreparer(accountName, flushFilePath)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.flushResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// flushPreparer prepares the Flush request.
func (client Client) flushPreparer(accountName string, flushFilePath string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("POST", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "APPEND")
	params.Set("append", "true")
	params.Set("flush", "true")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// flushResponder handles the response to the Flush request.
func (client Client) flushResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// GetACLStatus gets Access Control List (ACL) entries for the specified file or directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. ACLFilePath is the Data Lake
// Store path (starting with '/') of the file or directory for which to get the ACL.
func (client Client) GetACLStatus(ctx context.Context, accountName string, ACLFilePath string) (*ACLStatusResult, error) {
	req, err := client.getACLStatusPreparer(accountName, ACLFilePath)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.getACLStatusResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*ACLStatusResult), err
}

// getACLStatusPreparer prepares the GetACLStatus request.
func (client Client) getACLStatusPreparer(accountName string, ACLFilePath string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "MSGETACLSTATUS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// getACLStatusResponder handles the response to the GetACLStatus request.
func (client Client) getACLStatusResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &ACLStatusResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// GetContentSummary gets the file content summary object specified by the file path.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. getContentSummaryFilePath is
// the Data Lake Store path (starting with '/') of the file for which to retrieve the summary.
func (client Client) GetContentSummary(ctx context.Context, accountName string, getContentSummaryFilePath string) (*ContentSummaryResult, error) {
	req, err := client.getContentSummaryPreparer(accountName, getContentSummaryFilePath)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.getContentSummaryResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*ContentSummaryResult), err
}

// getContentSummaryPreparer prepares the GetContentSummary request.
func (client Client) getContentSummaryPreparer(accountName string, getContentSummaryFilePath string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "GETCONTENTSUMMARY")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// getContentSummaryResponder handles the response to the GetContentSummary request.
func (client Client) getContentSummaryResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &ContentSummaryResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// GetFileStatus get the file status object specified by the file path.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. getFilePath is the Data Lake
// Store path (starting with '/') of the file or directory for which to retrieve the status.
func (client Client) GetFileStatus(ctx context.Context, accountName string, getFilePath string) (*FileStatusResult, error) {
	req, err := client.getFileStatusPreparer(accountName, getFilePath)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.getFileStatusResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileStatusResult), err
}

// getFileStatusPreparer prepares the GetFileStatus request.
func (client Client) getFileStatusPreparer(accountName string, getFilePath string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "MSGETFILESTATUS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// getFileStatusResponder handles the response to the GetFileStatus request.
func (client Client) getFileStatusResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileStatusResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// ListFileStatus get the list of file status objects specified by the file path, with optional pagination parameters
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. listFilePath is the Data Lake
// Store path (starting with '/') of the directory to list. listSize is gets or sets the number of items to return.
// Optional. listAfter is gets or sets the item or lexographical index after which to begin returning results. For
// example, a file list of 'a','b','d' and listAfter='b' will return 'd', and a listAfter='c' will also return 'd'.
// Optional. listBefore is gets or sets the item or lexographical index before which to begin returning results. For
// example, a file list of 'a','b','d' and listBefore='d' will return 'a','b', and a listBefore='c' will also return
// 'a','b'. Optional.
func (client Client) ListFileStatus(ctx context.Context, accountName string, listFilePath string, listSize *int32, listAfter *string, listBefore *string) (*FileStatusesResult, error) {
	req, err := client.listFileStatusPreparer(accountName, listFilePath, listSize, listAfter, listBefore)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.listFileStatusResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileStatusesResult), err
}

// listFileStatusPreparer prepares the ListFileStatus request.
func (client Client) listFileStatusPreparer(accountName string, listFilePath string, listSize *int32, listAfter *string, listBefore *string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if listSize != nil {
		params.Set("listSize", fmt.Sprintf("%v", *listSize))
	}
	if listAfter != nil {
		params.Set("listAfter", *listAfter)
	}
	if listBefore != nil {
		params.Set("listBefore", *listBefore)
	}
	params.Set("op", "MSLISTSTATUS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// listFileStatusResponder handles the response to the ListFileStatus request.
func (client Client) listFileStatusResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileStatusesResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// Mkdirs creates a directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the directory to create.
func (client Client) Mkdirs(ctx context.Context, accountName string, pathParameter string) (*FileOperationResult, error) {
	req, err := client.mkdirsPreparer(accountName, pathParameter)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.mkdirsResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileOperationResult), err
}

// mkdirsPreparer prepares the Mkdirs request.
func (client Client) mkdirsPreparer(accountName string, pathParameter string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "MKDIRS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// mkdirsResponder handles the response to the Mkdirs request.
func (client Client) mkdirsResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileOperationResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// ModifyACLEntries modifies existing Access Control List (ACL) entries on a file or folder.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. modifyACLFilePath is the Data
// Lake Store path (starting with '/') of the file or directory with the ACL being modified. aclspec is the ACL
// specification included in ACL modification operations in the format '[default:]user|group|other::r|-w|-x|-'
func (client Client) ModifyACLEntries(ctx context.Context, accountName string, modifyACLFilePath string, aclspec string) (*http.Response, error) {
	req, err := client.modifyACLEntriesPreparer(accountName, modifyACLFilePath, aclspec)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.modifyACLEntriesResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// modifyACLEntriesPreparer prepares the ModifyACLEntries request.
func (client Client) modifyACLEntriesPreparer(accountName string, modifyACLFilePath string, aclspec string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("aclspec", aclspec)
	params.Set("op", "MODIFYACLENTRIES")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// modifyACLEntriesResponder handles the response to the ModifyACLEntries request.
func (client Client) modifyACLEntriesResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// MsConcat concatenates the list of source files into the destination file, deleting all source files upon success.
// This method accepts more source file paths than the Concat method. This method and the parameters it accepts are
// subject to change for usability in an upcoming version.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. msConcatDestinationPath is the
// Data Lake Store path (starting with '/') of the destination file resulting from the concatenation. streamContents is
// a list of Data Lake Store paths (starting with '/') of the source files. Must be in the format: sources=<comma
// separated list> streamContents will be closed upon successful return. Callers should ensure closure when receiving
// an error.deleteSourceDirectory is indicates that as an optimization instead of deleting each individual source
// stream, delete the source stream folder if all streams are in the same folder instead. This results in a substantial
// performance improvement when the only streams in the folder are part of the concatenation operation. WARNING: This
// includes the deletion of any other files that are not source files. Only set this to true when source files are the
// only files in the source directory.
func (client Client) MsConcat(ctx context.Context, accountName string, msConcatDestinationPath string, body io.ReadSeeker, deleteSourceDirectory *bool) (*http.Response, error) {
	if err := validate([]validation{
		{targetValue: streamContents,
			constraints: []constraint{{target: "streamContents", name: null, rule: true, chain: nil}}}}); err != nil {
		return nil, err
	}
	req, err := client.msConcatPreparer(accountName, msConcatDestinationPath, body, deleteSourceDirectory)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.msConcatResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// msConcatPreparer prepares the MsConcat request.
func (client Client) msConcatPreparer(accountName string, msConcatDestinationPath string, body io.ReadSeeker, deleteSourceDirectory *bool) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("POST", client.url, body)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if deleteSourceDirectory != nil {
		params.Set("deleteSourceDirectory", fmt.Sprintf("%v", *deleteSourceDirectory))
	}
	params.Set("op", "MSCONCAT")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// msConcatResponder handles the response to the MsConcat request.
func (client Client) msConcatResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Open opens and reads from the specified file.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. directFilePath is the Data
// Lake Store path (starting with '/') of the file to open.
func (client Client) Open(ctx context.Context, accountName string, directFilePath string, length *int64, offset *int64) (*OpenResponse, error) {
	req, err := client.openPreparer(accountName, directFilePath, length, offset)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.openResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*OpenResponse), err
}

// openPreparer prepares the Open request.
func (client Client) openPreparer(accountName string, directFilePath string, length *int64, offset *int64) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if length != nil {
		params.Set("length", fmt.Sprintf("%v", *length))
	}
	if offset != nil {
		params.Set("offset", fmt.Sprintf("%v", *offset))
	}
	params.Set("op", "OPEN")
	params.Set("read", "true")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// openResponder handles the response to the Open request.
func (client Client) openResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return &OpenResponse{rawResponse: resp.Response()}, err
}

// RemoveACL removes the existing Access Control List (ACL) of the specified file or directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. ACLFilePath is the Data Lake
// Store path (starting with '/') of the file or directory with the ACL being removed.
func (client Client) RemoveACL(ctx context.Context, accountName string, ACLFilePath string) (*http.Response, error) {
	req, err := client.removeACLPreparer(accountName, ACLFilePath)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.removeACLResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// removeACLPreparer prepares the RemoveACL request.
func (client Client) removeACLPreparer(accountName string, ACLFilePath string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "REMOVEACL")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// removeACLResponder handles the response to the RemoveACL request.
func (client Client) removeACLResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// RemoveACLEntries removes existing Access Control List (ACL) entries for a file or folder.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. removeACLFilePath is the Data
// Lake Store path (starting with '/') of the file or directory with the ACL being removed. aclspec is the ACL spec
// included in ACL removal operations in the format '[default:]user|group|other'
func (client Client) RemoveACLEntries(ctx context.Context, accountName string, removeACLFilePath string, aclspec string) (*http.Response, error) {
	req, err := client.removeACLEntriesPreparer(accountName, removeACLFilePath, aclspec)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.removeACLEntriesResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// removeACLEntriesPreparer prepares the RemoveACLEntries request.
func (client Client) removeACLEntriesPreparer(accountName string, removeACLFilePath string, aclspec string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("aclspec", aclspec)
	params.Set("op", "REMOVEACLENTRIES")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// removeACLEntriesResponder handles the response to the RemoveACLEntries request.
func (client Client) removeACLEntriesResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// RemoveDefaultACL removes the existing Default Access Control List (ACL) of the specified directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. defaultACLFilePath is the Data
// Lake Store path (starting with '/') of the directory with the default ACL being removed.
func (client Client) RemoveDefaultACL(ctx context.Context, accountName string, defaultACLFilePath string) (*http.Response, error) {
	req, err := client.removeDefaultACLPreparer(accountName, defaultACLFilePath)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.removeDefaultACLResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// removeDefaultACLPreparer prepares the RemoveDefaultACL request.
func (client Client) removeDefaultACLPreparer(accountName string, defaultACLFilePath string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "REMOVEDEFAULTACL")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// removeDefaultACLResponder handles the response to the RemoveDefaultACL request.
func (client Client) removeDefaultACLResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Rename rename a file or directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. renameFilePath is the Data
// Lake Store path (starting with '/') of the file or directory to move/rename. destination is the path to move/rename
// the file or folder to
func (client Client) Rename(ctx context.Context, accountName string, renameFilePath string, destination string) (*FileOperationResult, error) {
	req, err := client.renamePreparer(accountName, renameFilePath, destination)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.renameResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileOperationResult), err
}

// renamePreparer prepares the Rename request.
func (client Client) renamePreparer(accountName string, renameFilePath string, destination string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("destination", destination)
	params.Set("op", "RENAME")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// renameResponder handles the response to the Rename request.
func (client Client) renameResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileOperationResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// SetACL sets the Access Control List (ACL) for a file or folder.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. setACLFilePath is the Data
// Lake Store path (starting with '/') of the file or directory on which to set the ACL. aclspec is the ACL spec
// included in ACL creation operations in the format '[default:]user|group|other::r|-w|-x|-'
func (client Client) SetACL(ctx context.Context, accountName string, setACLFilePath string, aclspec string) (*http.Response, error) {
	req, err := client.setACLPreparer(accountName, setACLFilePath, aclspec)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.setACLResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// setACLPreparer prepares the SetACL request.
func (client Client) setACLPreparer(accountName string, setACLFilePath string, aclspec string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("aclspec", aclspec)
	params.Set("op", "SETACL")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// setACLResponder handles the response to the SetACL request.
func (client Client) setACLResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// SetFileExpiry sets or removes the expiration time on the specified file. This operation can only be executed against
// files. Folders are not supported.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. filePath is the Data Lake
// Store path (starting with '/') of the file on which to set or remove the expiration time. expiryOption is indicates
// the type of expiration to use for the file: 1. NeverExpire: ExpireTime is ignored. 2. RelativeToNow: ExpireTime is
// an integer in milliseconds representing the expiration date relative to when file expiration is updated. 3.
// RelativeToCreationDate: ExpireTime is an integer in milliseconds representing the expiration date relative to file
// creation. 4. Absolute: ExpireTime is an integer in milliseconds, as a Unix timestamp relative to 1/1/1970 00:00:00.
// expireTime is the time that the file will expire, corresponding to the ExpiryOption that was set.
func (client Client) SetFileExpiry(ctx context.Context, accountName string, filePath string, expiryOption ExpiryOptionType, expireTime *int64) (*http.Response, error) {
	req, err := client.setFileExpiryPreparer(accountName, filePath, expiryOption, expireTime)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.setFileExpiryResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// setFileExpiryPreparer prepares the SetFileExpiry request.
func (client Client) setFileExpiryPreparer(accountName string, filePath string, expiryOption ExpiryOptionType, expireTime *int64) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("expiryOption", fmt.Sprintf("%v", expiryOption))
	if expireTime != nil {
		params.Set("expireTime", fmt.Sprintf("%v", *expireTime))
	}
	params.Set("op", "SETEXPIRY")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// setFileExpiryResponder handles the response to the SetFileExpiry request.
func (client Client) setFileExpiryResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// SetOwner sets the owner of a file or directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. setOwnerFilePath is the Data
// Lake Store path (starting with '/') of the file or directory for which to set the owner. owner is the AAD Object ID
// of the user owner of the file or directory. If empty, the property will remain unchanged. group is the AAD Object ID
// of the group owner of the file or directory. If empty, the property will remain unchanged.
func (client Client) SetOwner(ctx context.Context, accountName string, setOwnerFilePath string, owner *string, group *string) (*http.Response, error) {
	req, err := client.setOwnerPreparer(accountName, setOwnerFilePath, owner, group)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.setOwnerResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// setOwnerPreparer prepares the SetOwner request.
func (client Client) setOwnerPreparer(accountName string, setOwnerFilePath string, owner *string, group *string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if owner != nil {
		params.Set("owner", *owner)
	}
	if group != nil {
		params.Set("group", *group)
	}
	params.Set("op", "SETOWNER")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// setOwnerResponder handles the response to the SetOwner request.
func (client Client) setOwnerResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// SetPermission sets the permission of the file or folder.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. setPermissionFilePath is the
// Data Lake Store path (starting with '/') of the file or directory for which to set the permission. permission is a
// string representation of the permission (i.e 'rwx'). If empty, this property remains unchanged.
func (client Client) SetPermission(ctx context.Context, accountName string, setPermissionFilePath string, permission *string) (*http.Response, error) {
	req, err := client.setPermissionPreparer(accountName, setPermissionFilePath, permission)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.setPermissionResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// setPermissionPreparer prepares the SetPermission request.
func (client Client) setPermissionPreparer(accountName string, setPermissionFilePath string, permission *string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if permission != nil {
		params.Set("permission", *permission)
	}
	params.Set("op", "SETPERMISSION")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// setPermissionResponder handles the response to the SetPermission request.
func (client Client) setPermissionResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}
