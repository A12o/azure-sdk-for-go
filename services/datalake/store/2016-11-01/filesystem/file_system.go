package filesystem

// Copyright (c) Microsoft and contributors.  All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

import (
	"context"
	"encoding/json"
	"fmt"
	"github.com/Azure/azure-pipeline-go/pipeline"
	uuid "github.com/satori/go.uuid"
	"io"
	"io/ioutil"
	"net/http"
	"net/url"
)

// Client is the creates an Azure Data Lake Store filesystem client.
type Client struct {
	ManagementClient
}

// NewClient creates an instance of the Client client.
func NewClient(url url.URL, p pipeline.Pipeline) Client {
	return Client{NewManagementClient(url, p)}
}

// Append used for serial appends to the specified file.Â NOTE: The target must not contain data added by
// ConcurrentAppend. ConcurrentAppend and Append cannot be used interchangeably; once a target file has been modified
// using either of these append options, the other append option cannot be used on the target file.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file to which to append. streamContents is the file contents to include when
// appending to the file. streamContents will be closed upon successful return. Callers should ensure closure when
// receiving an error.offset is the optional offset in the stream to begin the append operation. Default is to append
// at the end of the stream. syncFlag is optionally indicates what to do after completion of the concurrent append.
// DATA indicates that more data will be sent immediately by the client, the file handle should remain open/locked, and
// file metadata (including file length, last modified time) should NOT get updated. METADATA indicates that more data
// will be sent immediately by the client, the file handle should remain open/locked, and file metadata should get
// updated. CLOSE indicates that the client is done sending data, the file handle should be closed/unlocked, and file
// metadata should get updated. leaseID is optional unique GUID per file to ensure single writer semantics, meaning
// that only clients that append to the file with the same leaseId will be allowed to do so. fileSessionID is optional
// unique GUID per file indicating all the appends with the same fileSessionId are from the same client and same
// session. This will give a performance benefit when syncFlag is DATA or METADATA.
func (client Client) Append(ctx context.Context, accountName string, pathParameter string, body io.ReadSeeker, offset *int64, syncFlag SyncFlagType, leaseID *uuid.UUID, fileSessionID *uuid.UUID) (*http.Response, error) {
	if err := validate([]validation{
		{targetValue: streamContents,
			constraints: []constraint{{target: "streamContents", name: null, rule: true, chain: nil}}}}); err != nil {
		return nil, err
	}
	req, err := client.appendPreparer(accountName, pathParameter, body, offset, syncFlag, leaseID, fileSessionID)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.appendResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// appendPreparer prepares the Append request.
func (client Client) appendPreparer(accountName string, pathParameter string, body io.ReadSeeker, offset *int64, syncFlag SyncFlagType, leaseID *uuid.UUID, fileSessionID *uuid.UUID) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("POST", client.url, body)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if offset != nil {
		params.Set("offset", fmt.Sprintf("%v", *offset))
	}
	if syncFlag != SyncFlagNone {
		params.Set("syncFlag", fmt.Sprintf("%v", syncFlag))
	}
	if leaseID != nil {
		params.Set("leaseId", fmt.Sprintf("%v", *leaseID))
	}
	if fileSessionID != nil {
		params.Set("fileSessionId", fmt.Sprintf("%v", *fileSessionID))
	}
	params.Set("append", "true")
	params.Set("op", "APPEND")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// appendResponder handles the response to the Append request.
func (client Client) appendResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// CheckAccess checks if the specified access is available at the given path.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory for which to check access. fsaction is file system operation
// read/write/execute in string form, matching regex pattern '[rwx-]{3}'
func (client Client) CheckAccess(ctx context.Context, accountName string, pathParameter string, fsaction string) (*http.Response, error) {
	req, err := client.checkAccessPreparer(accountName, pathParameter, fsaction)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.checkAccessResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// checkAccessPreparer prepares the CheckAccess request.
func (client Client) checkAccessPreparer(accountName string, pathParameter string, fsaction string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("fsaction", fsaction)
	params.Set("op", "CHECKACCESS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// checkAccessResponder handles the response to the CheckAccess request.
func (client Client) checkAccessResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Concat concatenates the list of source files into the destination file, removing all source files upon success.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the destination file resulting from the concatenation. sources is a list of comma
// separated Data Lake Store paths (starting with '/') of the files to concatenate, in the order in which they should
// be concatenated.
func (client Client) Concat(ctx context.Context, accountName string, pathParameter string, sources []string) (*http.Response, error) {
	if err := validate([]validation{
		{targetValue: sources,
			constraints: []constraint{{target: "sources", name: null, rule: true, chain: nil}}}}); err != nil {
		return nil, err
	}
	req, err := client.concatPreparer(accountName, pathParameter, sources)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.concatResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// concatPreparer prepares the Concat request.
func (client Client) concatPreparer(accountName string, pathParameter string, sources []string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("POST", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("sources", fmt.Sprintf("%v", sources, ","))
	params.Set("op", "CONCAT")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// concatResponder handles the response to the Concat request.
func (client Client) concatResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// ConcurrentAppend appends to the specified file, optionally first creating the file if it does not yet exist. This
// method supports multiple concurrent appends to the file. NOTE: The target must not contain data added by Create or
// normal (serial) Append. ConcurrentAppend and Append cannot be used interchangeably; once a target file has been
// modified using either of these append options, the other append option cannot be used on the target file.
// ConcurrentAppend does not guarantee order and can result in duplicated data landing in the target file.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file to which to append using concurrent append. streamContents is the file
// contents to include when appending to the file. streamContents will be closed upon successful return. Callers should
// ensure closure when receiving an error.transferEncoding is indicates the data being sent to the server is being
// streamed in chunks. appendMode is indicates the concurrent append call should create the file if it doesn't exist or
// just open the existing file for append syncFlag is optionally indicates what to do after completion of the
// concurrent append. DATA indicates that more data will be sent immediately by the client, the file handle should
// remain open/locked, and file metadata (including file length, last modified time) should NOT get updated. METADATA
// indicates that more data will be sent immediately by the client, the file handle should remain open/locked, and file
// metadata should get updated. CLOSE indicates that the client is done sending data, the file handle should be
// closed/unlocked, and file metadata should get updated.
func (client Client) ConcurrentAppend(ctx context.Context, accountName string, pathParameter string, body io.ReadSeeker, transferEncoding string, appendMode AppendModeType, syncFlag SyncFlagType) (*http.Response, error) {
	if err := validate([]validation{
		{targetValue: streamContents,
			constraints: []constraint{{target: "streamContents", name: null, rule: true, chain: nil}}}}); err != nil {
		return nil, err
	}
	req, err := client.concurrentAppendPreparer(accountName, pathParameter, body, transferEncoding, appendMode, syncFlag)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.concurrentAppendResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// concurrentAppendPreparer prepares the ConcurrentAppend request.
func (client Client) concurrentAppendPreparer(accountName string, pathParameter string, body io.ReadSeeker, transferEncoding string, appendMode AppendModeType, syncFlag SyncFlagType) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("POST", client.url, body)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if appendMode != AppendModeNone {
		params.Set("appendMode", fmt.Sprintf("%v", appendMode))
	}
	params.Set("op", "CONCURRENTAPPEND")
	if syncFlag != SyncFlagNone {
		params.Set("syncFlag", fmt.Sprintf("%v", syncFlag))
	}
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	req.Header.Set("Transfer-Encoding", transferEncoding)
	return req, nil
}

// concurrentAppendResponder handles the response to the ConcurrentAppend request.
func (client Client) concurrentAppendResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Create creates a file with optionally specified content. NOTE: If content is provided, the resulting file cannot be
// modified using ConcurrentAppend.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file to create. streamContents is the file contents to include when creating
// the file. This parameter is optional, resulting in an empty file if not specified. streamContents will be closed
// upon successful return. Callers should ensure closure when receiving an error.overwrite is the indication of if the
// file should be overwritten. syncFlag is optionally indicates what to do after completion of the create. DATA
// indicates that more data will be sent immediately by the client, the file handle should remain open/locked, and file
// metadata (including file length, last modified time) should NOT get updated. METADATA indicates that more data will
// be sent immediately by the client, the file handle should remain open/locked, and file metadata should get updated.
// CLOSE indicates that the client is done sending data, the file handle should be closed/unlocked, and file metadata
// should get updated. leaseID is optional unique GUID per file to ensure single writer semantics, meaning that only
// clients that append to the file with the same leaseId will be allowed to do so. permission is the octal
// representation of the unnamed user, mask and other permissions that should be set for the file when created. If not
// specified, it inherits these from the container.
func (client Client) Create(ctx context.Context, accountName string, pathParameter string, body io.ReadSeeker, overwrite *bool, syncFlag SyncFlagType, leaseID *uuid.UUID, permission *int32) (*http.Response, error) {
	req, err := client.createPreparer(accountName, pathParameter, body, overwrite, syncFlag, leaseID, permission)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.createResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// createPreparer prepares the Create request.
func (client Client) createPreparer(accountName string, pathParameter string, body io.ReadSeeker, overwrite *bool, syncFlag SyncFlagType, leaseID *uuid.UUID, permission *int32) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, body)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if overwrite != nil {
		params.Set("overwrite", fmt.Sprintf("%v", *overwrite))
	}
	if syncFlag != SyncFlagNone {
		params.Set("syncFlag", fmt.Sprintf("%v", syncFlag))
	}
	if leaseID != nil {
		params.Set("leaseId", fmt.Sprintf("%v", *leaseID))
	}
	if permission != nil {
		params.Set("permission", fmt.Sprintf("%v", *permission))
	}
	params.Set("write", "true")
	params.Set("op", "CREATE")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// createResponder handles the response to the Create request.
func (client Client) createResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK, http.StatusCreated)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Delete deletes the requested file or directory, optionally recursively.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory to delete. recursive is the optional switch indicating if
// the delete should be recursive
func (client Client) Delete(ctx context.Context, accountName string, pathParameter string, recursive *bool) (*FileOperationResult, error) {
	req, err := client.deletePreparer(accountName, pathParameter, recursive)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.deleteResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileOperationResult), err
}

// deletePreparer prepares the Delete request.
func (client Client) deletePreparer(accountName string, pathParameter string, recursive *bool) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("DELETE", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if recursive != nil {
		params.Set("recursive", fmt.Sprintf("%v", *recursive))
	}
	params.Set("op", "DELETE")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// deleteResponder handles the response to the Delete request.
func (client Client) deleteResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileOperationResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// GetACLStatus gets Access Control List (ACL) entries for the specified file or directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory for which to get the ACL. tooID is an optional switch to
// return friendly names in place of object ID for ACL entries. tooid=false returns friendly names instead of the AAD
// Object ID. Default value is true, returning AAD object IDs.
func (client Client) GetACLStatus(ctx context.Context, accountName string, pathParameter string, tooID *bool) (*ACLStatusResult, error) {
	req, err := client.getACLStatusPreparer(accountName, pathParameter, tooID)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.getACLStatusResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*ACLStatusResult), err
}

// getACLStatusPreparer prepares the GetACLStatus request.
func (client Client) getACLStatusPreparer(accountName string, pathParameter string, tooID *bool) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if tooID != nil {
		params.Set("tooId", fmt.Sprintf("%v", *tooID))
	}
	params.Set("op", "GETACLSTATUS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// getACLStatusResponder handles the response to the GetACLStatus request.
func (client Client) getACLStatusResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &ACLStatusResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// GetContentSummary gets the file content summary object specified by the file path.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file for which to retrieve the summary.
func (client Client) GetContentSummary(ctx context.Context, accountName string, pathParameter string) (*ContentSummaryResult, error) {
	req, err := client.getContentSummaryPreparer(accountName, pathParameter)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.getContentSummaryResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*ContentSummaryResult), err
}

// getContentSummaryPreparer prepares the GetContentSummary request.
func (client Client) getContentSummaryPreparer(accountName string, pathParameter string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "GETCONTENTSUMMARY")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// getContentSummaryResponder handles the response to the GetContentSummary request.
func (client Client) getContentSummaryResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &ContentSummaryResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// GetFileStatus get the file status object specified by the file path.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory for which to retrieve the status. tooID is an optional
// switch to return friendly names in place of owner and group. tooid=false returns friendly names instead of the AAD
// Object ID. Default value is true, returning AAD object IDs.
func (client Client) GetFileStatus(ctx context.Context, accountName string, pathParameter string, tooID *bool) (*FileStatusResult, error) {
	req, err := client.getFileStatusPreparer(accountName, pathParameter, tooID)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.getFileStatusResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileStatusResult), err
}

// getFileStatusPreparer prepares the GetFileStatus request.
func (client Client) getFileStatusPreparer(accountName string, pathParameter string, tooID *bool) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if tooID != nil {
		params.Set("tooId", fmt.Sprintf("%v", *tooID))
	}
	params.Set("op", "GETFILESTATUS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// getFileStatusResponder handles the response to the GetFileStatus request.
func (client Client) getFileStatusResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileStatusResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// ListFileStatus get the list of file status objects specified by the file path, with optional pagination parameters
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the directory to list. listSize is gets or sets the number of items to return.
// Optional. listAfter is gets or sets the item or lexographical index after which to begin returning results. For
// example, a file list of 'a','b','d' and listAfter='b' will return 'd', and a listAfter='c' will also return 'd'.
// Optional. listBefore is gets or sets the item or lexographical index before which to begin returning results. For
// example, a file list of 'a','b','d' and listBefore='d' will return 'a','b', and a listBefore='c' will also return
// 'a','b'. Optional. tooID is an optional switch to return friendly names in place of owner and group. tooid=false
// returns friendly names instead of the AAD Object ID. Default value is true, returning AAD object IDs.
func (client Client) ListFileStatus(ctx context.Context, accountName string, pathParameter string, listSize *int32, listAfter *string, listBefore *string, tooID *bool) (*FileStatusesResult, error) {
	req, err := client.listFileStatusPreparer(accountName, pathParameter, listSize, listAfter, listBefore, tooID)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.listFileStatusResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileStatusesResult), err
}

// listFileStatusPreparer prepares the ListFileStatus request.
func (client Client) listFileStatusPreparer(accountName string, pathParameter string, listSize *int32, listAfter *string, listBefore *string, tooID *bool) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if listSize != nil {
		params.Set("listSize", fmt.Sprintf("%v", *listSize))
	}
	if listAfter != nil {
		params.Set("listAfter", *listAfter)
	}
	if listBefore != nil {
		params.Set("listBefore", *listBefore)
	}
	if tooID != nil {
		params.Set("tooId", fmt.Sprintf("%v", *tooID))
	}
	params.Set("op", "LISTSTATUS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// listFileStatusResponder handles the response to the ListFileStatus request.
func (client Client) listFileStatusResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileStatusesResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// Mkdirs creates a directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the directory to create. permission is optional octal permission with which the
// directory should be created.
func (client Client) Mkdirs(ctx context.Context, accountName string, pathParameter string, permission *int32) (*FileOperationResult, error) {
	req, err := client.mkdirsPreparer(accountName, pathParameter, permission)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.mkdirsResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileOperationResult), err
}

// mkdirsPreparer prepares the Mkdirs request.
func (client Client) mkdirsPreparer(accountName string, pathParameter string, permission *int32) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if permission != nil {
		params.Set("permission", fmt.Sprintf("%v", *permission))
	}
	params.Set("op", "MKDIRS")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// mkdirsResponder handles the response to the Mkdirs request.
func (client Client) mkdirsResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileOperationResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// ModifyACLEntries modifies existing Access Control List (ACL) entries on a file or folder.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory with the ACL being modified. aclspec is the ACL
// specification included in ACL modification operations in the format '[default:]user|group|other::r|-w|-x|-'
func (client Client) ModifyACLEntries(ctx context.Context, accountName string, pathParameter string, aclspec string) (*http.Response, error) {
	req, err := client.modifyACLEntriesPreparer(accountName, pathParameter, aclspec)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.modifyACLEntriesResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// modifyACLEntriesPreparer prepares the ModifyACLEntries request.
func (client Client) modifyACLEntriesPreparer(accountName string, pathParameter string, aclspec string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("aclspec", aclspec)
	params.Set("op", "MODIFYACLENTRIES")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// modifyACLEntriesResponder handles the response to the ModifyACLEntries request.
func (client Client) modifyACLEntriesResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// MsConcat concatenates the list of source files into the destination file, deleting all source files upon success.
// This method accepts more source file paths than the Concat method. This method and the parameters it accepts are
// subject to change for usability in an upcoming version.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the destination file resulting from the concatenation. streamContents is a list of
// Data Lake Store paths (starting with '/') of the source files. Must be a comma-separated path list in the format:
// sources=/file/path/1.txt,/file/path/2.txt,/file/path/lastfile.csv streamContents will be closed upon successful
// return. Callers should ensure closure when receiving an error.deleteSourceDirectory is indicates that as an
// optimization instead of deleting each individual source stream, delete the source stream folder if all streams are
// in the same folder instead. This results in a substantial performance improvement when the only streams in the
// folder are part of the concatenation operation. WARNING: This includes the deletion of any other files that are not
// source files. Only set this to true when source files are the only files in the source directory.
func (client Client) MsConcat(ctx context.Context, accountName string, pathParameter string, body io.ReadSeeker, deleteSourceDirectory *bool) (*http.Response, error) {
	if err := validate([]validation{
		{targetValue: streamContents,
			constraints: []constraint{{target: "streamContents", name: null, rule: true, chain: nil}}}}); err != nil {
		return nil, err
	}
	req, err := client.msConcatPreparer(accountName, pathParameter, body, deleteSourceDirectory)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.msConcatResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// msConcatPreparer prepares the MsConcat request.
func (client Client) msConcatPreparer(accountName string, pathParameter string, body io.ReadSeeker, deleteSourceDirectory *bool) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("POST", client.url, body)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if deleteSourceDirectory != nil {
		params.Set("deleteSourceDirectory", fmt.Sprintf("%v", *deleteSourceDirectory))
	}
	params.Set("op", "MSCONCAT")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// msConcatResponder handles the response to the MsConcat request.
func (client Client) msConcatResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Open opens and reads from the specified file.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file to open. length is the number of bytes that the server will attempt to
// retrieve. It will retrieve <= length bytes. offset is the byte offset to start reading data from. fileSessionID is
// optional unique GUID per file indicating all the reads with the same fileSessionId are from the same client and same
// session. This will give a performance benefit.
func (client Client) Open(ctx context.Context, accountName string, pathParameter string, length *int64, offset *int64, fileSessionID *uuid.UUID) (*OpenResponse, error) {
	req, err := client.openPreparer(accountName, pathParameter, length, offset, fileSessionID)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.openResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*OpenResponse), err
}

// openPreparer prepares the Open request.
func (client Client) openPreparer(accountName string, pathParameter string, length *int64, offset *int64, fileSessionID *uuid.UUID) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("GET", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if length != nil {
		params.Set("length", fmt.Sprintf("%v", *length))
	}
	if offset != nil {
		params.Set("offset", fmt.Sprintf("%v", *offset))
	}
	if fileSessionID != nil {
		params.Set("fileSessionId", fmt.Sprintf("%v", *fileSessionID))
	}
	params.Set("read", "true")
	params.Set("op", "OPEN")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// openResponder handles the response to the Open request.
func (client Client) openResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return &OpenResponse{rawResponse: resp.Response()}, err
}

// RemoveACL removes the existing Access Control List (ACL) of the specified file or directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory with the ACL being removed.
func (client Client) RemoveACL(ctx context.Context, accountName string, pathParameter string) (*http.Response, error) {
	req, err := client.removeACLPreparer(accountName, pathParameter)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.removeACLResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// removeACLPreparer prepares the RemoveACL request.
func (client Client) removeACLPreparer(accountName string, pathParameter string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "REMOVEACL")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// removeACLResponder handles the response to the RemoveACL request.
func (client Client) removeACLResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// RemoveACLEntries removes existing Access Control List (ACL) entries for a file or folder.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory with the ACL being removed. aclspec is the ACL spec included
// in ACL removal operations in the format '[default:]user|group|other'
func (client Client) RemoveACLEntries(ctx context.Context, accountName string, pathParameter string, aclspec string) (*http.Response, error) {
	req, err := client.removeACLEntriesPreparer(accountName, pathParameter, aclspec)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.removeACLEntriesResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// removeACLEntriesPreparer prepares the RemoveACLEntries request.
func (client Client) removeACLEntriesPreparer(accountName string, pathParameter string, aclspec string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("aclspec", aclspec)
	params.Set("op", "REMOVEACLENTRIES")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// removeACLEntriesResponder handles the response to the RemoveACLEntries request.
func (client Client) removeACLEntriesResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// RemoveDefaultACL removes the existing Default Access Control List (ACL) of the specified directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the directory with the default ACL being removed.
func (client Client) RemoveDefaultACL(ctx context.Context, accountName string, pathParameter string) (*http.Response, error) {
	req, err := client.removeDefaultACLPreparer(accountName, pathParameter)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.removeDefaultACLResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// removeDefaultACLPreparer prepares the RemoveDefaultACL request.
func (client Client) removeDefaultACLPreparer(accountName string, pathParameter string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("op", "REMOVEDEFAULTACL")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// removeDefaultACLResponder handles the response to the RemoveDefaultACL request.
func (client Client) removeDefaultACLResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// Rename rename a file or directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory to move/rename. destination is the path to move/rename the
// file or folder to
func (client Client) Rename(ctx context.Context, accountName string, pathParameter string, destination string) (*FileOperationResult, error) {
	req, err := client.renamePreparer(accountName, pathParameter, destination)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.renameResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.(*FileOperationResult), err
}

// renamePreparer prepares the Rename request.
func (client Client) renamePreparer(accountName string, pathParameter string, destination string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("destination", destination)
	params.Set("op", "RENAME")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// renameResponder handles the response to the Rename request.
func (client Client) renameResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	result := &FileOperationResult{rawResponse: resp.Response()}
	if err != nil {
		return result, err
	}
	defer resp.Response().Body.Close()
	b, err := ioutil.ReadAll(resp.Response().Body)
	if err != nil {
		return result, NewResponseError(err, resp.Response(), "failed to read response body")
	}
	if len(b) > 0 {
		err = json.Unmarshal(b, result)
		if err != nil {
			return result, NewResponseError(err, resp.Response(), "failed to unmarshal response body")
		}
	}
	return result, nil
}

// SetACL sets the Access Control List (ACL) for a file or folder.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory on which to set the ACL. aclspec is the ACL spec included in
// ACL creation operations in the format '[default:]user|group|other::r|-w|-x|-'
func (client Client) SetACL(ctx context.Context, accountName string, pathParameter string, aclspec string) (*http.Response, error) {
	req, err := client.setACLPreparer(accountName, pathParameter, aclspec)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.setACLResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// setACLPreparer prepares the SetACL request.
func (client Client) setACLPreparer(accountName string, pathParameter string, aclspec string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("aclspec", aclspec)
	params.Set("op", "SETACL")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// setACLResponder handles the response to the SetACL request.
func (client Client) setACLResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// SetFileExpiry sets or removes the expiration time on the specified file. This operation can only be executed against
// files. Folders are not supported.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file on which to set or remove the expiration time. expiryOption is indicates
// the type of expiration to use for the file: 1. NeverExpire: ExpireTime is ignored. 2. RelativeToNow: ExpireTime is
// an integer in milliseconds representing the expiration date relative to when file expiration is updated. 3.
// RelativeToCreationDate: ExpireTime is an integer in milliseconds representing the expiration date relative to file
// creation. 4. Absolute: ExpireTime is an integer in milliseconds, as a Unix timestamp relative to 1/1/1970 00:00:00.
// expireTime is the time that the file will expire, corresponding to the ExpiryOption that was set.
func (client Client) SetFileExpiry(ctx context.Context, accountName string, pathParameter string, expiryOption ExpiryOptionType, expireTime *int64) (*http.Response, error) {
	req, err := client.setFileExpiryPreparer(accountName, pathParameter, expiryOption, expireTime)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.setFileExpiryResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// setFileExpiryPreparer prepares the SetFileExpiry request.
func (client Client) setFileExpiryPreparer(accountName string, pathParameter string, expiryOption ExpiryOptionType, expireTime *int64) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	params.Set("expiryOption", fmt.Sprintf("%v", expiryOption))
	if expireTime != nil {
		params.Set("expireTime", fmt.Sprintf("%v", *expireTime))
	}
	params.Set("op", "SETEXPIRY")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// setFileExpiryResponder handles the response to the SetFileExpiry request.
func (client Client) setFileExpiryResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// SetOwner sets the owner of a file or directory.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory for which to set the owner. owner is the AAD Object ID of
// the user owner of the file or directory. If empty, the property will remain unchanged. group is the AAD Object ID of
// the group owner of the file or directory. If empty, the property will remain unchanged.
func (client Client) SetOwner(ctx context.Context, accountName string, pathParameter string, owner *string, group *string) (*http.Response, error) {
	req, err := client.setOwnerPreparer(accountName, pathParameter, owner, group)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.setOwnerResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// setOwnerPreparer prepares the SetOwner request.
func (client Client) setOwnerPreparer(accountName string, pathParameter string, owner *string, group *string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if owner != nil {
		params.Set("owner", *owner)
	}
	if group != nil {
		params.Set("group", *group)
	}
	params.Set("op", "SETOWNER")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// setOwnerResponder handles the response to the SetOwner request.
func (client Client) setOwnerResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}

// SetPermission sets the permission of the file or folder.
//
// accountName is the Azure Data Lake Store account to execute filesystem operations on. pathParameter is the Data Lake
// Store path (starting with '/') of the file or directory for which to set the permission. permission is a string
// representation of the permission (i.e 'rwx'). If empty, this property remains unchanged.
func (client Client) SetPermission(ctx context.Context, accountName string, pathParameter string, permission *string) (*http.Response, error) {
	req, err := client.setPermissionPreparer(accountName, pathParameter, permission)
	if err != nil {
		return nil, err
	}
	resp, err := client.Pipeline().Do(ctx, responderPolicyFactory{responder: client.setPermissionResponder}, req)
	if err != nil {
		return nil, err
	}
	return resp.Response(), err
}

// setPermissionPreparer prepares the SetPermission request.
func (client Client) setPermissionPreparer(accountName string, pathParameter string, permission *string) (pipeline.Request, error) {
	req, err := pipeline.NewRequest("PUT", client.url, nil)
	if err != nil {
		return req, pipeline.NewError(err, "failed to create request")
	}
	params := req.URL.Query()
	if permission != nil {
		params.Set("permission", *permission)
	}
	params.Set("op", "SETPERMISSION")
	params.Set("api-version", APIVersion)
	req.URL.RawQuery = params.Encode()
	return req, nil
}

// setPermissionResponder handles the response to the SetPermission request.
func (client Client) setPermissionResponder(resp pipeline.Response) (pipeline.Response, error) {
	err := validateResponse(resp, http.StatusOK)
	if resp == nil {
		return nil, err
	}
	return resp, err
}
